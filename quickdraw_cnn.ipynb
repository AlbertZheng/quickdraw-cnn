{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw-cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/AlbertZheng/quickdraw-cnn/blob/master/quickdraw_cnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qs0seV43MwNv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## \"You draw, I guess.\" is a MVP (Minimium Viable Product) that uses CNN to recognize the sketch drawings on web canvas.\n",
        "### The CNN was trained to recognize 10 classes using <a href='https://github.com/googlecreativelab/quickdraw-dataset'>\"The Quick, Draw! Dataset\" </a> of Google awesome \"猜画小歌\" Wechat App."
      ]
    },
    {
      "metadata": {
        "id": "0_FT6bGsOY22",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install dependent packages"
      ]
    },
    {
      "metadata": {
        "id": "EDJoFej9MZ83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "fea684c8-d819-4d57-f90d-d76c2b5f46d3"
      },
      "cell_type": "code",
      "source": [
        "!pip install \"tensorlayer>=1.10\"\n",
        "!pip install tensorflowjs\n",
        "!pip list|grep tensor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorlayer>=1.10 in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (0.14.1)\n",
            "Requirement already satisfied: requests<2.20,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (2.19.1)\n",
            "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (1.1.0)\n",
            "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (4.2.5)\n",
            "Requirement already satisfied: tqdm<4.26,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (4.25.0)\n",
            "Requirement already satisfied: matplotlib<2.3,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (2.2.3)\n",
            "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (1.15.1)\n",
            "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (3.38.0)\n",
            "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (1.10.11)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (0.19.2)\n",
            "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer>=1.10) (2.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (0.5.6)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (1.0.1)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (5.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (1.11.0)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer>=1.10) (0.19.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer>=1.10) (2018.8.24)\n",
            "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer>=1.10) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer>=1.10) (3.0.4)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.20,>=2.19->tensorlayer>=1.10) (2.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer>=1.10) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer>=1.10) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer>=1.10) (2.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer>=1.10) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<2.3,>=2.2->tensorlayer>=1.10) (0.10.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer>=1.10) (2.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer>=1.10) (4.3.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=0.9.0->scikit-image<0.15,>=0.14->tensorlayer>=1.10) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib<2.3,>=2.2->tensorlayer>=1.10) (39.1.0)\n",
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tensorflow==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: keras==2.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (1.0.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (0.31.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (39.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.11.0->tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs) (0.14.1)\n",
            "tensorboard              1.11.0   \n",
            "tensorflow               1.11.0   \n",
            "tensorflow-hub           0.1.1    \n",
            "tensorflowjs             0.6.2    \n",
            "tensorlayer              1.10.1   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QV6AypOzOiws",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import dependences, and check if GPU is available"
      ]
    },
    {
      "metadata": {
        "id": "W4-1-Q-EOi8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "83808906-f22e-4b2e-b793-4fa5a5a665ff"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "from tensorlayer.layers import *\n",
        "from tensorflow.python import debug as tfdebug\n",
        "\n",
        "\"\"\" Notice to put ```import matplotlib.pyplot``` after imports of tensorlayer, \n",
        "otherwise you will get below warning:\n",
        "\n",
        "This call to matplotlib.use() has no effect because the backend has already\n",
        "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
        "or matplotlib.backends is imported for the first time.\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print('### device name: {} ###'.format(device_name))\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('*** GPU device not found ***')\n",
        "print('### Found GPU at: {} ###'.format(device_name))\n",
        "\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "tl.logging.set_verbosity(tl.logging.DEBUG)\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config.gpu_options.allow_growth = True\n",
        "config.allow_soft_placement = True\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### device name: /device:GPU:0 ###\n",
            "### Found GPU at: /device:GPU:0 ###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q27izcVnPcQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the Quick, Draw dataset"
      ]
    },
    {
      "metadata": {
        "id": "QeDBh_7WPc0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        },
        "outputId": "1a8d1974-12c7-493a-ca6f-bb299408219e"
      },
      "cell_type": "code",
      "source": [
        "working_directory = 'data'\n",
        "dataset_directory = 'data/quickdraw'\n",
        "# categories_filename = 'categories.txt'\n",
        "# categories_file_url_source = 'https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/'\n",
        "\n",
        "# npy_dataset_url_source = 'https://storage.cloud.google.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "npy_dataset_url_source = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "\n",
        "X = \"X\"\n",
        "y = \"y\"\n",
        "\n",
        "X_NUMPY_DTYPE = np.float32\n",
        "y_NUMPY_DTYPE = np.int64\n",
        "X_TF_DTYPE = tf.float32\n",
        "y_TF_DTYPE = tf.int32\n",
        "\n",
        "image_height = 28\n",
        "image_width = 28\n",
        "image_depth = 1\n",
        "image_size = image_height * image_width * image_depth\n",
        "input_layer_X_shape = [image_height, image_width, image_depth]\n",
        "input_layer_X_shape_batch = [-1, image_height, image_width, image_depth]\n",
        "\n",
        "mini_categories_file_url_source = 'https://raw.githubusercontent.com/AlbertZheng/quickdraw-cnn/master/web/'\n",
        "mini_categories_filename = 'mini-categories.txt'\n",
        "n_category = 10  # The maximum of category number is up to 345\n",
        "n_train_example_per_category = 100000\n",
        "\n",
        "\n",
        "def print_dataset_shape(X_name, X, y_name, y):\n",
        "    print(X_name + '.shape ', X.shape, end='\\t,\\t')\n",
        "    print(y_name + '.shape ', y.shape)\n",
        "    print('%s.dtype %s\\t,\\t%s.dtype %s' % (X_name, X.dtype, y_name, y.dtype))\n",
        "\n",
        "\n",
        "def show_image(X, y, categories):\n",
        "    plt.imshow(X.reshape(image_height, image_width), cmap=\"gray\", interpolation='nearest')\n",
        "    plt.title(f\"{categories[y]}(label: {y})\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def load_quickdraw_dataset(\n",
        "    n_category=10, n_train_example_per_category=20000\n",
        "):\n",
        "    \"\"\" Download the quick draw data set. \"\"\"\n",
        "    n_validation_example_per_category = int(n_train_example_per_category / 0.7 * 0.2)\n",
        "    n_test_example_per_category = int(n_train_example_per_category / 0.7 * 0.1)\n",
        "\n",
        "    # Download the categories file\n",
        "    tl.files.utils.maybe_download_and_extract(mini_categories_filename, dataset_directory, mini_categories_file_url_source)\n",
        "\n",
        "    tl.logging.info(\"Load or Download quick draw > {}\".format(dataset_directory))\n",
        "\n",
        "    train_set = {X: np.empty([0, image_size], dtype=X_NUMPY_DTYPE), y: np.empty([0], dtype=y_NUMPY_DTYPE)}\n",
        "    validation_set = {X: np.empty([0, image_size], dtype=X_NUMPY_DTYPE), y: np.empty([0], dtype=y_NUMPY_DTYPE)}\n",
        "    test_set = {X: np.empty([0, image_size], dtype=X_NUMPY_DTYPE), y: np.empty([0], dtype=y_NUMPY_DTYPE)}\n",
        "\n",
        "    category_names = [line.rstrip('\\n') for line in open(f\"{dataset_directory}/{mini_categories_filename}\")]\n",
        "    for category_index, category_name in enumerate(category_names):\n",
        "        if category_index == n_category:\n",
        "            break\n",
        "\n",
        "        category_names[category_index], _, _ = category_name.rpartition('=')\n",
        "        category_name = category_names[category_index]\n",
        "\n",
        "        filename = urllib.parse.quote(category_name) + '.npy'\n",
        "        tl.files.utils.maybe_download_and_extract(filename, dataset_directory, npy_dataset_url_source)\n",
        "\n",
        "        data = np.load(os.path.join(dataset_directory, filename))\n",
        "        size_per_category = data.shape[0]\n",
        "        labels = np.full(size_per_category, category_index)\n",
        "\n",
        "        print(f\"### Category '{category_name}' id:{category_index} dataset info ###\")\n",
        "        print_dataset_shape(\"data\", data, \"labels\", labels)\n",
        "\n",
        "        number_begin = 0\n",
        "        number_end = n_train_example_per_category\n",
        "        # train_set[X] = np.concatenate((train_set[X], data[number_begin: number_end, :]), axis=0)\n",
        "        train_set[X] = np.vstack((train_set[X], data[number_begin: number_end, :]))\n",
        "        train_set[y] = np.append(train_set[y], labels[number_begin: number_end])\n",
        "\n",
        "        number_begin += n_train_example_per_category\n",
        "        number_end += n_validation_example_per_category\n",
        "        # validation_set[X] = np.concatenate((validation_set[X], data[number_begin:number_end, :]), axis=0)\n",
        "        validation_set[X] = np.vstack((validation_set[X], data[number_begin:number_end, :]))\n",
        "        validation_set[y] = np.append(validation_set[y], labels[number_begin:number_end])\n",
        "\n",
        "        number_begin += n_validation_example_per_category\n",
        "        number_end += n_test_example_per_category\n",
        "        # test_set[X] = np.concatenate((test_set[X], data[number_begin:number_end, :]), axis=0)\n",
        "        test_set[X] = np.vstack((test_set[X], data[number_begin:number_end, :]))\n",
        "        test_set[y] = np.append(test_set[y], labels[number_begin:number_end])\n",
        "\n",
        "        print_dataset_shape(\"train_set[X]\", train_set[X], \"train_set[y]\", train_set[y])\n",
        "        print_dataset_shape(\"validation_set[X]\", validation_set[X], \"validation_set[y]\", validation_set[y])\n",
        "        print_dataset_shape(\"test_set[X]\", test_set[X], \"test_set[y]\", test_set[y])\n",
        "\n",
        "    # Randomize the dataset\n",
        "    size_per_set = train_set[X].shape[0]\n",
        "    permutation = np.random.permutation(size_per_set)\n",
        "    train_set[X] = train_set[X][permutation, :]\n",
        "    train_set[y] = train_set[y][permutation]\n",
        "\n",
        "    size_per_set = validation_set[X].shape[0]\n",
        "    permutation = np.random.permutation(size_per_set)\n",
        "    validation_set[X] = validation_set[X][permutation, :]\n",
        "    validation_set[y] = validation_set[y][permutation]\n",
        "\n",
        "    size_per_set = test_set[X].shape[0]\n",
        "    permutation = np.random.permutation(size_per_set)\n",
        "    test_set[X] = test_set[X][permutation, :]\n",
        "    test_set[y] = test_set[y][permutation]\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    train_set[X] = train_set[X].reshape(input_layer_X_shape_batch)\n",
        "    validation_set[X] = validation_set[X].reshape(input_layer_X_shape_batch)\n",
        "    test_set[X] = test_set[X].reshape(input_layer_X_shape_batch)\n",
        "\n",
        "    # The original grayscale image is 'black background (x==0) and gray~white (0< x <=255) brush'\n",
        "    # Because the CNN model doesn't need to learn the grayscale values and it only needs to\n",
        "    # learn the strokes, we normalize it to 'white background (x==1) and block (x==0) brush'.\n",
        "    train_set[X] = 1.0 - np.ceil(train_set[X] / 255.0)\n",
        "    validation_set[X] = 1.0 - np.ceil(validation_set[X] / 255.0)\n",
        "    test_set[X] = 1.0 - np.ceil(test_set[X] / 255.0)\n",
        "\n",
        "    return category_names, train_set, validation_set, test_set\n",
        "\n",
        "\n",
        "# Open TensorBoard logs writer\n",
        "tfboard_file_writer = tf.summary.FileWriter('logs')\n",
        "\n",
        "# Download data\n",
        "category_names, train_set, validation_set, test_set = load_quickdraw_dataset(n_category, n_train_example_per_category)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TL] Load or Download quick draw > data/quickdraw\n",
            "### Category 'airplane' id:0 dataset info ###\n",
            "data.shape  (151623, 784)\t,\tlabels.shape  (151623,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (100000, 784)\t,\ttrain_set[y].shape  (100000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (28571, 784)\t,\tvalidation_set[y].shape  (28571,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (14285, 784)\t,\ttest_set[y].shape  (14285,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'alarm clock' id:1 dataset info ###\n",
            "data.shape  (123399, 784)\t,\tlabels.shape  (123399,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (200000, 784)\t,\ttrain_set[y].shape  (200000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (51970, 784)\t,\tvalidation_set[y].shape  (51970,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (14285, 784)\t,\ttest_set[y].shape  (14285,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'apple' id:2 dataset info ###\n",
            "data.shape  (144722, 784)\t,\tlabels.shape  (144722,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (300000, 784)\t,\ttrain_set[y].shape  (300000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (80541, 784)\t,\tvalidation_set[y].shape  (80541,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (28570, 784)\t,\ttest_set[y].shape  (28570,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'bicycle' id:3 dataset info ###\n",
            "data.shape  (126527, 784)\t,\tlabels.shape  (126527,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (400000, 784)\t,\ttrain_set[y].shape  (400000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (107068, 784)\t,\tvalidation_set[y].shape  (107068,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (28570, 784)\t,\ttest_set[y].shape  (28570,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'car' id:4 dataset info ###\n",
            "data.shape  (182764, 784)\t,\tlabels.shape  (182764,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (500000, 784)\t,\ttrain_set[y].shape  (500000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (135639, 784)\t,\tvalidation_set[y].shape  (135639,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (42855, 784)\t,\ttest_set[y].shape  (42855,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'cloud' id:5 dataset info ###\n",
            "data.shape  (120265, 784)\t,\tlabels.shape  (120265,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (600000, 784)\t,\ttrain_set[y].shape  (600000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (155904, 784)\t,\tvalidation_set[y].shape  (155904,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (42855, 784)\t,\ttest_set[y].shape  (42855,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'cup' id:6 dataset info ###\n",
            "data.shape  (130721, 784)\t,\tlabels.shape  (130721,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (700000, 784)\t,\ttrain_set[y].shape  (700000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (184475, 784)\t,\tvalidation_set[y].shape  (184475,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (45005, 784)\t,\ttest_set[y].shape  (45005,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'dog' id:7 dataset info ###\n",
            "data.shape  (152159, 784)\t,\tlabels.shape  (152159,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (800000, 784)\t,\ttrain_set[y].shape  (800000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (213046, 784)\t,\tvalidation_set[y].shape  (213046,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (59290, 784)\t,\ttest_set[y].shape  (59290,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 'eyeglasses' id:8 dataset info ###\n",
            "data.shape  (225762, 784)\t,\tlabels.shape  (225762,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (900000, 784)\t,\ttrain_set[y].shape  (900000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (241617, 784)\t,\tvalidation_set[y].shape  (241617,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (73575, 784)\t,\ttest_set[y].shape  (73575,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n",
            "### Category 't-shirt' id:9 dataset info ###\n",
            "data.shape  (125233, 784)\t,\tlabels.shape  (125233,)\n",
            "data.dtype uint8\t,\tlabels.dtype int64\n",
            "train_set[X].shape  (1000000, 784)\t,\ttrain_set[y].shape  (1000000,)\n",
            "train_set[X].dtype float32\t,\ttrain_set[y].dtype int64\n",
            "validation_set[X].shape  (266850, 784)\t,\tvalidation_set[y].shape  (266850,)\n",
            "validation_set[X].dtype float32\t,\tvalidation_set[y].dtype int64\n",
            "test_set[X].shape  (73575, 784)\t,\ttest_set[y].shape  (73575,)\n",
            "test_set[X].dtype float32\t,\ttest_set[y].dtype int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LejFWzHKP2Dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function: Network model definition"
      ]
    },
    {
      "metadata": {
        "id": "d5TwN6-sP1eQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_batch_normalization(X_batch, y_batch, output_units, reuse, is_train):\n",
        "    \"\"\" Define the network model \"\"\"\n",
        "    W_init1 = tf.truncated_normal_initializer(stddev=5e-2)\n",
        "    W_init2 = tf.truncated_normal_initializer(stddev=0.04)\n",
        "    bias_init = tf.constant_initializer(value=0.1)\n",
        "\n",
        "    with tf.variable_scope(\"model\", reuse=reuse):\n",
        "        net = InputLayer(X_batch, name='input')\n",
        "        net = Conv2d(net, 64, (5, 5), (1, 1), padding='SAME',\n",
        "                     W_init=W_init1, b_init=None, name='cnn1')\n",
        "        net = BatchNormLayer(net, is_train, act=tf.nn.relu, name='batch1')\n",
        "        net = MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')\n",
        "\n",
        "        net = Conv2d(net, 64, (5, 5), (1, 1), padding='SAME',\n",
        "                     W_init=W_init1, b_init=None, name='cnn2')\n",
        "        net = BatchNormLayer(net, is_train, act=tf.nn.relu, name='batch2')\n",
        "        net = MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')\n",
        "\n",
        "        net = FlattenLayer(net, name='flatten')\n",
        "        net = DenseLayer(net, 384, act=tf.nn.relu,\n",
        "                         W_init=W_init2, b_init=bias_init, name='d1relu')\n",
        "        net = DenseLayer(net, 192, act=tf.nn.relu,\n",
        "                         W_init=W_init2, b_init=bias_init, name='d2relu')\n",
        "        # The softmax() is implemented internally in tl.cost.cross_entropy(y, y_) to\n",
        "        # speed up computation, so we use identity here.\n",
        "        # see tf.nn.sparse_softmax_cross_entropy_with_logits()\n",
        "        net = DenseLayer(net, n_units=output_units, act=None,\n",
        "                         W_init=W_init2, name='output')\n",
        "\n",
        "        y_prediction_batch_without_softmax = net.outputs\n",
        "\n",
        "        # For inference by using this model\n",
        "        # y_output = tf.argmax(tf.nn.softmax(y_prediction_batch_without_softmax), 1)\n",
        "        y_output = tf.nn.softmax(y_prediction_batch_without_softmax, name=\"y_output\")\n",
        "\n",
        "        ce = tl.cost.cross_entropy(y_prediction_batch_without_softmax, y_batch, name='cost')\n",
        "\n",
        "        \"\"\" 需给后面的全连接层引入L2 normalization，惩罚模型的复杂度，避免overfitting \"\"\"\n",
        "        # L2 for the MLP, without this, the accuracy will be reduced by 15%.\n",
        "        L2 = 0\n",
        "        for p in tl.layers.get_variables_with_name('relu/W', True, True):\n",
        "            L2 += tf.contrib.layers.l2_regularizer(0.004)(p)\n",
        "        # 加上L2模型复杂度惩罚项后，得到最终真正的cost\n",
        "        cost = ce + L2\n",
        "\n",
        "        correct_prediction = tf.equal(tf.cast(tf.argmax(y_prediction_batch_without_softmax, 1), y_TF_DTYPE), y_batch)\n",
        "        # correct_prediction = tf.Print(correct_prediction, [correct_prediction], \"correct_prediction: \")\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        return net, cost, accuracy, y_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jpISk8SQqCO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Train, validate and test"
      ]
    },
    {
      "metadata": {
        "id": "3iOAaIdbQoQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4865
        },
        "outputId": "13bd1377-678b-47aa-ee50-189b41a978cf"
      },
      "cell_type": "code",
      "source": [
        "# Train, validate and test\n",
        "batch_size = 128\n",
        "n_epoch = 25\n",
        "n_step_per_epoch = int(len(train_set[y]) / batch_size)\n",
        "n_step = n_epoch * n_step_per_epoch\n",
        "print_freq = 1\n",
        "checkpoint_freq = 3\n",
        "learning_rate = 0.0001\n",
        "\n",
        "model_ckpt_file_name = os.path.join(working_directory, \"checkpoint\", \"model-quickdraw-cnn.ckpt\")\n",
        "resume = True  # load model, resume from previous checkpoint?\n",
        "\n",
        "\n",
        "def distort_fn(X, is_train=False):\n",
        "    # print('begin', X.shape, np.min(X), np.max(X))\n",
        "\n",
        "    if is_train == True:\n",
        "        # 1. Randomly flip the image horizontally.\n",
        "        X = tf.image.random_flip_left_right(X)\n",
        "\n",
        "    # X = tf.image.per_image_standardization(X)\n",
        "\n",
        "    # print('after norm', X.shape, np.min(X), np.max(X), np.mean(X))\n",
        "    return X\n",
        "\n",
        "\n",
        "def save_model():\n",
        "    model_type = \"saved-model\"\n",
        "    latest_model_directory = f'{model_type}-{time.strftime(\"%Y%m%d%H%M%S\", time.localtime())}'\n",
        "    saved_model_directory = os.path.join(working_directory, latest_model_directory)\n",
        "    if not os.path.exists(saved_model_directory):\n",
        "        tf.saved_model.simple_save(session, saved_model_directory,\n",
        "                                   inputs={\"X\": X_batch_ph},\n",
        "                                   outputs={\"y_output\": y_prediction_})\n",
        "        dist_directory = os.path.join(\".\", model_type)\n",
        "        if os.path.exists(dist_directory):\n",
        "            os.remove(dist_directory)\n",
        "        os.symlink(saved_model_directory, dist_directory, target_is_directory=True)\n",
        "\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    session = tf.Session(config=config)\n",
        "\n",
        "    #\n",
        "    # Connect to tfdbg dashboard by ```http://localhost:6006#debugger```\n",
        "    # when the following command is issued.\n",
        "    #\n",
        "    # ```bash\n",
        "    # $ tensorboard --logdir logs --port 6006 --debugger_port 6064\n",
        "    # ```\n",
        "    #\n",
        "    # session = tfdebug.TensorBoardDebugWrapperSession(session, \"albert-mbp.local:6064\")\n",
        "\n",
        "    X_batch_ph = tf.placeholder(dtype=X_TF_DTYPE, shape=[None, image_height, image_width, image_depth], name='X_batch')\n",
        "    y_batch_ph = tf.placeholder(dtype=y_TF_DTYPE, shape=[None], name='y_batch')\n",
        "    # X_batch_ph = tf.placeholder(dtype=X_TF_DTYPE, shape=[batch_size, image_height, image_width, image_depth], name='X')\n",
        "    # y_batch_ph = tf.placeholder(dtype=y_TF_DTYPE, shape=[batch_size], name='y')\n",
        "\n",
        "    def perform_minibatch(run_list, X, y, batch_size, is_train=False):\n",
        "        n_batch, sum_loss, sum_accuracy = 0, 0, 0\n",
        "        for X_batch_a, y_batch_a in tl.iterate.minibatches(X, y, batch_size, shuffle=is_train):\n",
        "            # data augmentation for training\n",
        "            # X_batch_a = tl.prepro.threading_data(X_batch_a, fn=distort_fn, is_train=is_train)\n",
        "\n",
        "            cost, accuracy = 0, 0\n",
        "            if is_train:\n",
        "                _, cost, accuracy = session.run(\n",
        "                    run_list, feed_dict={X_batch_ph: X_batch_a, y_batch_ph: y_batch_a}\n",
        "                )\n",
        "            else:\n",
        "                cost, accuracy = session.run(\n",
        "                    run_list, feed_dict={X_batch_ph: X_batch_a, y_batch_ph: y_batch_a}\n",
        "                )\n",
        "\n",
        "            sum_loss += cost\n",
        "            sum_accuracy += accuracy\n",
        "            n_batch += 1\n",
        "        return n_batch, sum_loss, sum_accuracy\n",
        "\n",
        "\n",
        "    with tf.device('/gpu:0'):  # <-- remove it if you don't have GPU\n",
        "        # Build the model\n",
        "        print(\"### Train Network model ###\")\n",
        "        network_, cost_, accuracy_, y_prediction_ = model_batch_normalization(\n",
        "            X_batch_ph, y_batch_ph, n_category, reuse=None, is_train=True\n",
        "        )\n",
        "        print(\"### Reuse this Train Network model for validation and test ###\")\n",
        "        _, cost_test_, accuracy_test_, y_prediction_test_ = model_batch_normalization(\n",
        "            X_batch_ph, y_batch_ph, n_category, reuse=True, is_train=False\n",
        "        )\n",
        "\n",
        "    # Define the training optimizer\n",
        "    with tf.device('/gpu:0'):  # <-- remove it if you don't have GPU\n",
        "        train_op_ = tf.train.AdamOptimizer(learning_rate).minimize(cost_)\n",
        "\n",
        "    tl.layers.initialize_global_variables(session)\n",
        "\n",
        "    # Attach the graph for TensorBoard writer\n",
        "    # tfboard_file_writer.add_graph(tf.get_default_graph())\n",
        "    tfboard_file_writer.add_graph(session.graph)\n",
        "\n",
        "    if resume and os.path.isfile(model_ckpt_file_name):\n",
        "        print(\"Load existing model \" + \"!\" * 10)\n",
        "        saver = tf.train.Saver()\n",
        "        saver.restore(session, model_ckpt_file_name)\n",
        "\n",
        "    print(\"### Network parameters ###\")\n",
        "    network_.print_params(False)\n",
        "    print(\"### Network layers ###\")\n",
        "    network_.print_layers()\n",
        "\n",
        "    print('   learning_rate: %f' % learning_rate)\n",
        "    print('   batch_size: %d' % batch_size)\n",
        "    print('   n_epoch: %d, step in an epoch: %d, total n_step: %d' % (n_epoch, n_step_per_epoch, n_step))\n",
        "\n",
        "    step, sum_batch, sum_loss, sum_accuracy = 0, 0, 0, 0\n",
        "    for epoch in range(n_epoch):\n",
        "        start_time = time.time()\n",
        "\n",
        "        n_batch_a_epoch, cost_a_epoch, accuracy_a_epoch = perform_minibatch(\n",
        "            [train_op_, cost_, accuracy_],\n",
        "            train_set[X], train_set[y], batch_size, is_train=True\n",
        "        )\n",
        "        sum_batch += n_batch_a_epoch\n",
        "        sum_loss += cost_a_epoch\n",
        "        sum_accuracy += accuracy_a_epoch\n",
        "        step += n_batch_a_epoch\n",
        "\n",
        "        assert n_batch_a_epoch == n_step_per_epoch\n",
        "\n",
        "        if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
        "            print(\"Epoch %d : Step %d-%d of %d took %fs\" %\n",
        "                  (epoch + 1, step - n_step_per_epoch, step, n_step, time.time() - start_time))\n",
        "            print(\"   train loss: %f\" % (sum_loss / sum_batch))\n",
        "            print(\"   train accuracy: %f\" % (sum_accuracy / sum_batch))\n",
        "            sum_batch, sum_loss, sum_accuracy = 0, 0, 0\n",
        "\n",
        "            n_batch_a_epoch, cost_a_epoch, accuracy_a_epoch = perform_minibatch(\n",
        "                [cost_test_, accuracy_test_],\n",
        "                validation_set[X], validation_set[y], batch_size\n",
        "            )\n",
        "            print(\"   validation loss: %f\" % (cost_a_epoch / n_batch_a_epoch))\n",
        "            print(\"   validation accuracy: %f\" % (accuracy_a_epoch / n_batch_a_epoch))\n",
        "\n",
        "            n_batch_a_epoch, cost_a_epoch, accuracy_a_epoch = perform_minibatch(\n",
        "                [cost_test_, accuracy_test_],\n",
        "                test_set[X], test_set[y], batch_size\n",
        "            )\n",
        "            print(\"   test loss: %f\" % (cost_a_epoch / n_batch_a_epoch))\n",
        "            print(\"   test accuracy: %f\" % (accuracy_a_epoch / n_batch_a_epoch))\n",
        "\n",
        "        # Save model when checkpoint\n",
        "        if (epoch + 1) % checkpoint_freq == 0:\n",
        "            print(\"Saving checkpoint... \" + \"!\" * 10)\n",
        "            saver = tf.train.Saver()\n",
        "            save_path = saver.save(session, model_ckpt_file_name)\n",
        "            print(\"Saving model... \" + \"!\" * 10)\n",
        "            save_model()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Train Network model ###\n",
            "[TL] InputLayer  model/input: (?, 28, 28, 1)\n",
            "[TL] Conv2d model/cnn1: n_filter: 64 filter_size: (5, 5) strides: (1, 1) pad: SAME act: No Activation\n",
            "[TL] BatchNormLayer model/batch1: decay: 1.000000 epsilon: 0.000010 act: relu is_train: False\n",
            "[TL] MaxPool2d model/pool1: filter_size: (3, 3) strides: (2, 2) padding: SAME\n",
            "[TL] Conv2d model/cnn2: n_filter: 64 filter_size: (5, 5) strides: (1, 1) pad: SAME act: No Activation\n",
            "[TL] BatchNormLayer model/batch2: decay: 1.000000 epsilon: 0.000010 act: relu is_train: False\n",
            "[TL] MaxPool2d model/pool2: filter_size: (3, 3) strides: (2, 2) padding: SAME\n",
            "[TL] FlattenLayer model/flatten: 3136\n",
            "[TL] DenseLayer  model/d1relu: 384 relu\n",
            "[TL] DenseLayer  model/d2relu: 192 relu\n",
            "[TL] DenseLayer  model/output: 10 No Activation\n",
            "[TL]   [*] geting variables with relu/W\n",
            "[TL]   got   0: model/d1relu/W:0   (3136, 384)\n",
            "[TL]   got   1: model/d2relu/W:0   (384, 192)\n",
            "### Reuse this Train Network model for validation and test ###\n",
            "[TL] InputLayer  model/input: (?, 28, 28, 1)\n",
            "[TL] Conv2d model/cnn1: n_filter: 64 filter_size: (5, 5) strides: (1, 1) pad: SAME act: No Activation\n",
            "[TL] BatchNormLayer model/batch1: decay: 0.000000 epsilon: 0.000010 act: relu is_train: False\n",
            "[TL] MaxPool2d model/pool1: filter_size: (3, 3) strides: (2, 2) padding: SAME\n",
            "[TL] Conv2d model/cnn2: n_filter: 64 filter_size: (5, 5) strides: (1, 1) pad: SAME act: No Activation\n",
            "[TL] BatchNormLayer model/batch2: decay: 0.000000 epsilon: 0.000010 act: relu is_train: False\n",
            "[TL] MaxPool2d model/pool2: filter_size: (3, 3) strides: (2, 2) padding: SAME\n",
            "[TL] FlattenLayer model/flatten: 3136\n",
            "[TL] DenseLayer  model/d1relu: 384 relu\n",
            "[TL] DenseLayer  model/d2relu: 192 relu\n",
            "[TL] DenseLayer  model/output: 10 No Activation\n",
            "[TL]   [*] geting variables with relu/W\n",
            "[TL]   got   0: model/d1relu/W:0   (3136, 384)\n",
            "[TL]   got   1: model/d2relu/W:0   (384, 192)\n",
            "[TL] WARNING: Function: `tensorlayer.layers.utils.initialize_global_variables` (in file: /usr/local/lib/python3.6/dist-packages/tensorlayer/layers/utils.py) is deprecated and will be removed after 2018-09-30.\n",
            "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
            "\n",
            "### Network parameters ###\n",
            "[TL]   param   0: model/cnn1/kernel:0  (5, 5, 1, 64)      float32_ref\n",
            "[TL]   param   1: model/batch1/beta:0  (64,)              float32_ref\n",
            "[TL]   param   2: model/batch1/gamma:0 (64,)              float32_ref\n",
            "[TL]   param   3: model/batch1/moving_mean:0 (64,)              float32_ref\n",
            "[TL]   param   4: model/batch1/moving_variance:0 (64,)              float32_ref\n",
            "[TL]   param   5: model/cnn2/kernel:0  (5, 5, 64, 64)     float32_ref\n",
            "[TL]   param   6: model/batch2/beta:0  (64,)              float32_ref\n",
            "[TL]   param   7: model/batch2/gamma:0 (64,)              float32_ref\n",
            "[TL]   param   8: model/batch2/moving_mean:0 (64,)              float32_ref\n",
            "[TL]   param   9: model/batch2/moving_variance:0 (64,)              float32_ref\n",
            "[TL]   param  10: model/d1relu/W:0     (3136, 384)        float32_ref\n",
            "[TL]   param  11: model/d1relu/b:0     (384,)             float32_ref\n",
            "[TL]   param  12: model/d2relu/W:0     (384, 192)         float32_ref\n",
            "[TL]   param  13: model/d2relu/b:0     (192,)             float32_ref\n",
            "[TL]   param  14: model/output/W:0     (192, 10)          float32_ref\n",
            "[TL]   param  15: model/output/b:0     (10,)              float32_ref\n",
            "[TL]   num of params: 1384970\n",
            "### Network layers ###\n",
            "[TL]   layer   0: X_batch:0            (?, 28, 28, 1)     float32\n",
            "[TL]   layer   1: model/cnn1/Conv2D:0  (?, 28, 28, 64)    float32\n",
            "[TL]   layer   2: model/batch1/Relu:0  (?, 28, 28, 64)    float32\n",
            "[TL]   layer   3: model/pool1/MaxPool:0 (?, 14, 14, 64)    float32\n",
            "[TL]   layer   4: model/cnn2/Conv2D:0  (?, 14, 14, 64)    float32\n",
            "[TL]   layer   5: model/batch2/Relu:0  (?, 14, 14, 64)    float32\n",
            "[TL]   layer   6: model/pool2/MaxPool:0 (?, 7, 7, 64)      float32\n",
            "[TL]   layer   7: model/flatten:0      (?, 3136)          float32\n",
            "[TL]   layer   8: model/d1relu/Relu:0  (?, 384)           float32\n",
            "[TL]   layer   9: model/d2relu/Relu:0  (?, 192)           float32\n",
            "[TL]   layer  10: model/output/bias_add:0 (?, 10)            float32\n",
            "   learning_rate: 0.000100\n",
            "   batch_size: 128\n",
            "   n_epoch: 25, step in an epoch: 7812, total n_step: 195300\n",
            "Epoch 1 : Step 0-7812 of 195300 took 152.987222s\n",
            "   train loss: 0.825091\n",
            "   train accuracy: 0.889975\n",
            "   validation loss: 0.346009\n",
            "   validation accuracy: 0.924859\n",
            "   test loss: 0.392011\n",
            "   test accuracy: 0.908836\n",
            "Epoch 2 : Step 7812-15624 of 195300 took 151.574701s\n",
            "   train loss: 0.293687\n",
            "   train accuracy: 0.931787\n",
            "   validation loss: 0.258945\n",
            "   validation accuracy: 0.938224\n",
            "   test loss: 0.282494\n",
            "   test accuracy: 0.930177\n",
            "Epoch 3 : Step 15624-23436 of 195300 took 151.795451s\n",
            "   train loss: 0.245897\n",
            "   train accuracy: 0.939520\n",
            "   validation loss: 0.232319\n",
            "   validation accuracy: 0.942430\n",
            "   test loss: 0.250569\n",
            "   test accuracy: 0.936520\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007071807/saved_model.pb\n",
            "Epoch 4 : Step 23436-31248 of 195300 took 151.874032s\n",
            "   train loss: 0.223865\n",
            "   train accuracy: 0.943742\n",
            "   validation loss: 0.217335\n",
            "   validation accuracy: 0.945665\n",
            "   test loss: 0.241358\n",
            "   test accuracy: 0.936874\n",
            "Epoch 5 : Step 31248-39060 of 195300 took 151.989481s\n",
            "   train loss: 0.211334\n",
            "   train accuracy: 0.946428\n",
            "   validation loss: 0.209867\n",
            "   validation accuracy: 0.946538\n",
            "   test loss: 0.223694\n",
            "   test accuracy: 0.941869\n",
            "Epoch 6 : Step 39060-46872 of 195300 took 151.895644s\n",
            "   train loss: 0.202285\n",
            "   train accuracy: 0.948214\n",
            "   validation loss: 0.205358\n",
            "   validation accuracy: 0.947483\n",
            "   test loss: 0.227716\n",
            "   test accuracy: 0.939297\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007072651/saved_model.pb\n",
            "Epoch 7 : Step 46872-54684 of 195300 took 152.100858s\n",
            "   train loss: 0.195564\n",
            "   train accuracy: 0.949627\n",
            "   validation loss: 0.197817\n",
            "   validation accuracy: 0.949110\n",
            "   test loss: 0.210663\n",
            "   test accuracy: 0.944945\n",
            "Epoch 8 : Step 54684-62496 of 195300 took 151.926214s\n",
            "   train loss: 0.190717\n",
            "   train accuracy: 0.950761\n",
            "   validation loss: 0.195890\n",
            "   validation accuracy: 0.949481\n",
            "   test loss: 0.208820\n",
            "   test accuracy: 0.944305\n",
            "Epoch 9 : Step 62496-70308 of 195300 took 151.927302s\n",
            "   train loss: 0.186121\n",
            "   train accuracy: 0.951875\n",
            "   validation loss: 0.197613\n",
            "   validation accuracy: 0.948563\n",
            "   test loss: 0.212386\n",
            "   test accuracy: 0.943325\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007073536/saved_model.pb\n",
            "Epoch 10 : Step 70308-78120 of 195300 took 151.861172s\n",
            "   train loss: 0.182238\n",
            "   train accuracy: 0.952994\n",
            "   validation loss: 0.195331\n",
            "   validation accuracy: 0.949088\n",
            "   test loss: 0.223583\n",
            "   test accuracy: 0.939038\n",
            "Epoch 11 : Step 78120-85932 of 195300 took 151.916243s\n",
            "   train loss: 0.179818\n",
            "   train accuracy: 0.953353\n",
            "   validation loss: 0.186727\n",
            "   validation accuracy: 0.951877\n",
            "   test loss: 0.210932\n",
            "   test accuracy: 0.942958\n",
            "Epoch 12 : Step 85932-93744 of 195300 took 152.238724s\n",
            "   train loss: 0.176913\n",
            "   train accuracy: 0.954141\n",
            "   validation loss: 0.188309\n",
            "   validation accuracy: 0.950857\n",
            "   test loss: 0.208282\n",
            "   test accuracy: 0.943257\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007074420/saved_model.pb\n",
            "Epoch 13 : Step 93744-101556 of 195300 took 152.050377s\n",
            "   train loss: 0.174387\n",
            "   train accuracy: 0.954662\n",
            "   validation loss: 0.192215\n",
            "   validation accuracy: 0.949309\n",
            "   test loss: 0.229048\n",
            "   test accuracy: 0.936520\n",
            "Epoch 14 : Step 101556-109368 of 195300 took 152.028829s\n",
            "   train loss: 0.172213\n",
            "   train accuracy: 0.955294\n",
            "   validation loss: 0.187689\n",
            "   validation accuracy: 0.950643\n",
            "   test loss: 0.205360\n",
            "   test accuracy: 0.943938\n",
            "Epoch 15 : Step 109368-117180 of 195300 took 151.865213s\n",
            "   train loss: 0.170298\n",
            "   train accuracy: 0.955814\n",
            "   validation loss: 0.183896\n",
            "   validation accuracy: 0.952038\n",
            "   test loss: 0.194819\n",
            "   test accuracy: 0.946919\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007075304/saved_model.pb\n",
            "Epoch 16 : Step 117180-124992 of 195300 took 151.921346s\n",
            "   train loss: 0.168564\n",
            "   train accuracy: 0.956244\n",
            "   validation loss: 0.183061\n",
            "   validation accuracy: 0.952090\n",
            "   test loss: 0.201914\n",
            "   test accuracy: 0.944578\n",
            "Epoch 17 : Step 124992-132804 of 195300 took 152.007852s\n",
            "   train loss: 0.167177\n",
            "   train accuracy: 0.956595\n",
            "   validation loss: 0.182981\n",
            "   validation accuracy: 0.952147\n",
            "   test loss: 0.206890\n",
            "   test accuracy: 0.943135\n",
            "Epoch 18 : Step 132804-140616 of 195300 took 151.845572s\n",
            "   train loss: 0.165785\n",
            "   train accuracy: 0.957108\n",
            "   validation loss: 0.187885\n",
            "   validation accuracy: 0.950655\n",
            "   test loss: 0.217755\n",
            "   test accuracy: 0.939555\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007080149/saved_model.pb\n",
            "Epoch 19 : Step 140616-148428 of 195300 took 151.924293s\n",
            "   train loss: 0.164295\n",
            "   train accuracy: 0.957403\n",
            "   validation loss: 0.182009\n",
            "   validation accuracy: 0.952424\n",
            "   test loss: 0.199632\n",
            "   test accuracy: 0.945340\n",
            "Epoch 20 : Step 148428-156240 of 195300 took 151.887589s\n",
            "   train loss: 0.163076\n",
            "   train accuracy: 0.957781\n",
            "   validation loss: 0.182402\n",
            "   validation accuracy: 0.952094\n",
            "   test loss: 0.211167\n",
            "   test accuracy: 0.942141\n",
            "Epoch 21 : Step 156240-164052 of 195300 took 151.907967s\n",
            "   train loss: 0.162071\n",
            "   train accuracy: 0.958036\n",
            "   validation loss: 0.180620\n",
            "   validation accuracy: 0.952638\n",
            "   test loss: 0.205429\n",
            "   test accuracy: 0.943802\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007081033/saved_model.pb\n",
            "Epoch 22 : Step 164052-171864 of 195300 took 152.223937s\n",
            "   train loss: 0.160788\n",
            "   train accuracy: 0.958237\n",
            "   validation loss: 0.179531\n",
            "   validation accuracy: 0.952784\n",
            "   test loss: 0.202340\n",
            "   test accuracy: 0.944251\n",
            "Epoch 23 : Step 171864-179676 of 195300 took 151.991142s\n",
            "   train loss: 0.159759\n",
            "   train accuracy: 0.958725\n",
            "   validation loss: 0.182223\n",
            "   validation accuracy: 0.952128\n",
            "   test loss: 0.199317\n",
            "   test accuracy: 0.945272\n",
            "Epoch 24 : Step 179676-187488 of 195300 took 151.699486s\n",
            "   train loss: 0.158655\n",
            "   train accuracy: 0.959156\n",
            "   validation loss: 0.181203\n",
            "   validation accuracy: 0.952623\n",
            "   test loss: 0.202041\n",
            "   test accuracy: 0.944441\n",
            "Saving checkpoint... !!!!!!!!!!\n",
            "Saving model... !!!!!!!!!!\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007081917/saved_model.pb\n",
            "Epoch 25 : Step 187488-195300 of 195300 took 151.884693s\n",
            "   train loss: 0.157671\n",
            "   train accuracy: 0.959196\n",
            "   validation loss: 0.180380\n",
            "   validation accuracy: 0.952701\n",
            "   test loss: 0.190079\n",
            "   test accuracy: 0.948742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UbFcV5edSMlL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the trained model"
      ]
    },
    {
      "metadata": {
        "id": "4wFMK2v6SMvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29655e2b-5112-4145-d211-1b34c9374d1d"
      },
      "cell_type": "code",
      "source": [
        "save_model()\n",
        "\n",
        "tfboard_file_writer.flush()\n",
        "tfboard_file_writer.close()\n",
        "\n",
        "session.close()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: data/saved-model-20181007082727/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3e3lOIaaTd0s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert to TensorFlow.js web model"
      ]
    },
    {
      "metadata": {
        "id": "CrdV5utoTeB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "b1573895-afee-4c59-c6bb-59b7abc4f81c"
      },
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=tf_saved_model --output_node_names=\"model/y_output\" saved-model web-model\n",
        "!echo \"Current directory ->\"\n",
        "!ls -la\n",
        "!echo \"web-model directory ->\"\n",
        "!ls -la web-model\n",
        "!echo \"saved-model directory ->\"\n",
        "!ls -la saved-model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2018-10-07 08:28:53.836002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-10-07 08:28:53.836456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.44GiB\n",
            "2018-10-07 08:28:53.836499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-07 08:28:54.222424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-07 08:28:54.222500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-07 08:28:54.222531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-07 08:28:54.222862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-10-07 08:28:54.222953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10114 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2018-10-07 08:28:54.871941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: graph_to_optimize\n",
            "2018-10-07 08:28:54.872002: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   debug_stripper: Graph size after: 66 nodes (0), 67 edges (0), time = 0.063ms.\n",
            "2018-10-07 08:28:54.872029: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   model_pruner: Graph size after: 50 nodes (-16), 51 edges (-16), time = 0.314ms.\n",
            "2018-10-07 08:28:54.872050: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 30 nodes (-20), 29 edges (-22), time = 20.956ms.\n",
            "2018-10-07 08:28:54.872070: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   arithmetic_optimizer: Graph size after: 29 nodes (-1), 29 edges (0), time = 16.31ms.\n",
            "2018-10-07 08:28:54.872091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   dependency_optimizer: Graph size after: 26 nodes (-3), 25 edges (-4), time = 0.45ms.\n",
            "2018-10-07 08:28:54.872111: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   model_pruner: Graph size after: 26 nodes (0), 25 edges (0), time = 0.167ms.\n",
            "2018-10-07 08:28:54.872131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 26 nodes (0), 25 edges (0), time = 3.862ms.\n",
            "2018-10-07 08:28:54.872151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   arithmetic_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 6.481ms.\n",
            "2018-10-07 08:28:54.872171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   dependency_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 0.357ms.\n",
            "2018-10-07 08:28:54.872192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   debug_stripper: Graph size after: 26 nodes (0), 25 edges (0), time = 0.117ms.\n",
            "2018-10-07 08:28:54.872212: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   model_pruner: Graph size after: 26 nodes (0), 25 edges (0), time = 0.171ms.\n",
            "2018-10-07 08:28:54.872232: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 26 nodes (0), 25 edges (0), time = 3.52ms.\n",
            "2018-10-07 08:28:54.872252: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   arithmetic_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 6.33ms.\n",
            "2018-10-07 08:28:54.872272: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   dependency_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 0.337ms.\n",
            "2018-10-07 08:28:54.872292: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   model_pruner: Graph size after: 26 nodes (0), 25 edges (0), time = 0.181ms.\n",
            "2018-10-07 08:28:54.872312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 26 nodes (0), 25 edges (0), time = 4.454ms.\n",
            "2018-10-07 08:28:54.872332: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   arithmetic_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 6.433ms.\n",
            "2018-10-07 08:28:54.872352: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   dependency_optimizer: Graph size after: 26 nodes (0), 25 edges (0), time = 0.391ms.\n",
            "Writing weight file web-model/tensorflowjs_model.pb...\n",
            "2018-10-07 08:28:54.882702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-07 08:28:54.882772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-07 08:28:54.882803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-07 08:28:54.882846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-07 08:28:54.883137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10114 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Current directory ->\n",
            "total 16364\n",
            "drwxr-xr-x  1 root root     4096 Oct  7 08:27 .\n",
            "drwxr-xr-x  1 root root     4096 Oct  7 01:03 ..\n",
            "drwxr-xr-x  4 root root     4096 Sep 28 23:11 .config\n",
            "drwxr-xr-x 92 root root     4096 Oct  7 08:27 data\n",
            "drwxr-xr-x  2 root root     4096 Oct  7 07:09 logs\n",
            "drwxr-xr-x  2 root root     4096 Sep 28 23:32 sample_data\n",
            "lrwxrwxrwx  1 root root       31 Oct  7 08:27 saved-model -> data/saved-model-20181007082727\n",
            "-rw-r--r--  1 root root 11650483 Oct  7 05:22 saved-model.zip\n",
            "drwxr-xr-x  2 root root     4096 Oct  7 08:28 web-model\n",
            "-rw-r--r--  1 root root  5071314 Oct  7 05:22 web-model.zip\n",
            "web-model directory ->\n",
            "total 5836\n",
            "drwxr-xr-x 2 root root    4096 Oct  7 08:28 .\n",
            "drwxr-xr-x 1 root root    4096 Oct  7 08:27 ..\n",
            "-rw-r--r-- 1 root root 4194304 Oct  7 08:28 group1-shard1of2\n",
            "-rw-r--r-- 1 root root 1343536 Oct  7 08:28 group1-shard2of2\n",
            "-rw-r--r-- 1 root root  418453 Oct  7 08:28 tensorflowjs_model.pb\n",
            "-rw-r--r-- 1 root root     706 Oct  7 08:28 weights_manifest.json\n",
            "saved-model directory ->\n",
            "lrwxrwxrwx 1 root root 31 Oct  7 08:27 saved-model -> data/saved-model-20181007082727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q8g244v4VZUj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Zip and download the models"
      ]
    },
    {
      "metadata": {
        "id": "0fzcYLP3VB97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ef933093-9762-45d4-ef0b-2983ea6a67b3"
      },
      "cell_type": "code",
      "source": [
        "!zip -r web-model.zip web-model\n",
        "!zip -r saved-model.zip saved-model\n",
        "!ls -la *.zip\n",
        "\n",
        "from google.colab import files\n",
        "files.download('web-model.zip')\n",
        "files.download('saved-model.zip')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: web-model/ (stored 0%)\n",
            "updating: web-model/weights_manifest.json (deflated 71%)\n",
            "updating: web-model/tensorflowjs_model.pb (deflated 7%)\n",
            "updating: web-model/group1-shard2of2 (deflated 7%)\n",
            "updating: web-model/group1-shard1of2 (deflated 7%)\n",
            "updating: saved-model/ (stored 0%)\n",
            "updating: saved-model/variables/ (stored 0%)\n",
            "updating: saved-model/variables/variables.data-00000-of-00001 (deflated 28%)\n",
            "updating: saved-model/variables/variables.index (deflated 47%)\n",
            "updating: saved-model/saved_model.pb (deflated 91%)\n",
            "-rw-r--r-- 1 root root 11968332 Oct  7 08:31 saved-model.zip\n",
            "-rw-r--r-- 1 root root  5543711 Oct  7 08:31 web-model.zip\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}